# KV-Cache Offloading Architecture

**Distributed Endpoint Architecture for KV-Cache Offloading in LLM Inference**

---

## âš ï¸ CONFIDENTIAL & PROPRIETARY

**Â© 2025 Subramaniyam (Sam) Pooni. All Rights Reserved.**

This documentation contains proprietary and confidential information belonging to Subramaniyam (Sam) Pooni. Unauthorized reproduction, distribution, or disclosure of this material is strictly prohibited without prior written consent.

---

ğŸ“– **[View Live Documentation](https://YOUR-USERNAME.github.io/kv-cache-docs/)**

## Key Results

| Metric | Improvement |
|--------|-------------|
| Memory Expansion | 6Ã— |
| User Capacity | 8Ã— |
| HBM Hit Rate | 95% |
| Cost Reduction | 36% |
| TTFT Speedup | 15.6Ã— |
| Latency vs PCIe | 65Ã— faster |

## Documentation Structure

```
â”œâ”€â”€ index.html                    # Main landing page
â”œâ”€â”€ css/style.css                 # Shared stylesheet
â”œâ”€â”€ chapters/                     # 14 chapters
â”‚   â”œâ”€â”€ ch00-executive-summary.html
â”‚   â”œâ”€â”€ ch01-introduction.html
â”‚   â”œâ”€â”€ ch02-background.html
â”‚   â”œâ”€â”€ ch03-architecture.html
â”‚   â”œâ”€â”€ ch04-latency.html
â”‚   â”œâ”€â”€ ch05-bandwidth.html
â”‚   â”œâ”€â”€ ch06-preprocessing.html
â”‚   â”œâ”€â”€ ch07-kv-cache.html
â”‚   â”œâ”€â”€ ch08-moe.html
â”‚   â”œâ”€â”€ ch09-gpu-integration.html
â”‚   â”œâ”€â”€ ch10-market.html
â”‚   â”œâ”€â”€ ch11-performance.html
â”‚   â”œâ”€â”€ ch12-implementation.html
â”‚   â””â”€â”€ ch13-conclusion.html
â””â”€â”€ appendix/                     # 10 technical appendices
    â”œâ”€â”€ index.html
    â”œâ”€â”€ a-transformer-fundamentals.html
    â”œâ”€â”€ b-attention-mechanism.html
    â”œâ”€â”€ c-kv-cache-math.html
    â”œâ”€â”€ d-rope-encoding.html
    â”œâ”€â”€ e-head-specialization.html
    â”œâ”€â”€ f-cxl-technology.html
    â”œâ”€â”€ g-ema-algorithm.html
    â”œâ”€â”€ h-memory-hierarchy.html
    â”œâ”€â”€ i-bandwidth-calculations.html
    â””â”€â”€ j-implementation-reference.html
```

## Core Innovations

1. **Per-Head Attention Tracking** â€” Track KV-cache importance at head granularity
2. **EMA-Based Scoring** â€” Exponential moving average captures sustained importance
3. **RoPE-Aware Prefetch** â€” Exploit position encoding locality
4. **Controller-Resident Intelligence** â€” ARM cores in endpoints manage cache autonomously

## Technology Stack

- CXL 3.0 for cache-coherent memory access
- Computational Storage Devices (CSDs) with ARM cores
- 256 GB DDR5 + 4 TB NVMe per endpoint
- 4 endpoints provide 1 TB expansion at 256 GB/s

---

**Â© 2025 Subramaniyam (Sam) Pooni. All Rights Reserved.**

*Technical Documentation v3.0 â€” December 2025*

*CONFIDENTIAL â€” Do not distribute without authorization*
